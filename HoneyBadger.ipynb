{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the name of your first file including the file type extensionP1.xlsx\n",
      "Please enter the name of your second file including the file type extensionP2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "file = input(\"Please enter the name of your first file including the file type extension\")\n",
    "file1 = input(\"Please enter the name of your second file including the file type extension\")\n",
    "\n",
    "df = pd.read_excel(file, header = 0)\n",
    "df1 = pd.read_excel(file1, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report df contains 6 columns and 415 rows Report df1 contains 6 columns and 415 rows\n"
     ]
    }
   ],
   "source": [
    "#High level analysis message of the two data sets#\n",
    "\n",
    "print(\"Report df contains\", df.shape[1], \"columns and\" ,df.shape[0], \"rows \"\n",
    "     \"Report df1 contains\", df1.shape[1], \"columns and\", df1.shape[0], \"rows\")\n",
    "\n",
    "#Columns not matching#\n",
    "\n",
    "#Add code to identify columns with a . in it - use .split \n",
    "\n",
    "MSG = {'Row Summary': [[\"Report df contains\", df.shape[1], \"columns and\" ,df.shape[0], \"rows \"\n",
    "     \"Report df1 contains\", df1.shape[1], \"columns and\", df1.shape[0], \"rows\"]]}\n",
    "\n",
    "df6 = pd.DataFrame(MSG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success all columns are matching\n"
     ]
    }
   ],
   "source": [
    "#Detailed analysis of columns not matching\n",
    "\n",
    "#Define columns\n",
    "column_df = list(df.columns)\n",
    "column_df1 = list(df1.columns)\n",
    "\n",
    "\n",
    "#Columns not matching\n",
    "\n",
    "def check_missing_fields (column_df,column_df1):\n",
    "    set1 = set(column_df)\n",
    "    set2 = set(column_df1)\n",
    "    \n",
    "    #What this does is compare columns that are missing from both data sets\n",
    "    \n",
    "    missing = list(sorted(set1 - set2))\n",
    "    added = list(sorted(set2 - set1))\n",
    "  \n",
    " #Output appropriate message# \n",
    "\n",
    " \n",
    "    if len(missing) == 0 and len(added) != 0:\n",
    "    \n",
    "         print('there are no columns missing in df')\n",
    "         print('columns in df1 but not df', added)\n",
    "    \n",
    "    \n",
    "    elif len(added) == 0 and len(missing) !=0:\n",
    "    \n",
    "        print('there are no columns missing in df1')\n",
    "        print('columns in df but not df1', missing)\n",
    "        \n",
    "    elif len(added) == 0 and len(missing) ==0:\n",
    "         \n",
    "        print('Success all columns are matching')\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('columns in df but not df1', missing) \n",
    "        print('columns in df1 but not df', added)\n",
    "    \n",
    "    \n",
    "check_missing_fields (column_df,column_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which column do you wish to use as your unique idenitifier (UID)?Employee ID\n",
      "do you need another column to be concatenated?yes\n",
      "Which column do you wish to use as your unique idenitifier (UID)?Cost Center\n",
      "do you need another column to be concatenated?no\n"
     ]
    }
   ],
   "source": [
    "#Ask user to input columns that we want to concatenate as our UID#\n",
    "\n",
    "#Create a function that uses the variables from the step above to create a  UID in our DF#\n",
    "\n",
    "\n",
    "A = \"yes\"\n",
    "col = []\n",
    "listofcolumns = list()\n",
    "\n",
    "while A == \"yes\":\n",
    "    col = input(\"Which column do you wish to use as your unique idenitifier (UID)?\")\n",
    "    \n",
    "    listofcolumns.append(col)\n",
    "    \n",
    "    A = input(\"do you need another column to be concatenated?\").lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Employee ID', 'Cost Center']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sets the index based on the list#\n",
    "\n",
    "df.set_index(listofcolumns)\n",
    "df1.set_index(listofcolumns)\n",
    "\n",
    "print(listofcolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rows missing in DF1 compared to DF\n",
    "\n",
    "\n",
    "df2 = pd.merge(df,df1, on=listofcolumns,indicator=True, how='outer', suffixes=('_File1', '_File2'), validate='one_to_one', sort=True)\n",
    "\n",
    "df3 = df2[df2['_merge'] == 'right_only']\n",
    "\n",
    "#Rows missing in DF compared to DF1\n",
    "\n",
    "df4 = pd.merge(df,df1, on=listofcolumns,indicator=True, how='outer', suffixes=('_File1', '_File2'), validate='one_to_one', sort=True)\n",
    "\n",
    "df5 = df2[df2['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detailed analysis of columns against columns\n",
    "\n",
    "#Merge df and df1 for analysis\n",
    "df7 = pd.merge(df,df1, on=listofcolumns,indicator=True, how='outer', suffixes=('_File1', '_File2'), validate='one_to_one', sort=True)\n",
    "\n",
    "#Merge df and df1 for a consistent value on the number of columns\n",
    "df8 = pd.merge(df,df1, on=listofcolumns,indicator=True, how='outer', suffixes=('_File1', '_File2'), validate='one_to_one', sort=True)\n",
    "\n",
    "\n",
    "#Count columns\n",
    "df8columncount = df8.shape[1]\n",
    "\n",
    "\n",
    "#Create position reference for end of the DF\n",
    "\n",
    "endofDF = df8columncount\n",
    "\n",
    "#Where will the starting column always be?\n",
    "\n",
    "df9 = pd.DataFrame(listofcolumns)\n",
    "\n",
    "df9.shape[0]\n",
    "\n",
    "startingcolumn = df9.shape[0]\n",
    "\n",
    "#Create position ref1\n",
    "\n",
    "Position1 = startingcolumn\n",
    "\n",
    "#Create position ref2\n",
    "\n",
    "Position2 = 0\n",
    "\n",
    "#Create an object that references the first column by a variable\n",
    "\n",
    "Col1Position = df7.columns[Position1]\n",
    "\n",
    "#Create an object that references the second column\n",
    "\n",
    "Col2Position = df7.columns[Position2]\n",
    "\n",
    "#Create position ref1 trim, an object that removes the last 6 charachters from Col1Position\n",
    "\n",
    "Col1PositionTrimmed = Col1Position[:-6]\n",
    "\n",
    "#Create position ref2 trim,an object that removes the last 6 charachters from Col2Position\n",
    "\n",
    "Col2PositionTrimmed = Col2Position[:-6]\n",
    "\n",
    "#Create an object that shows the last 6 charachters\n",
    "\n",
    "Col1PositionTrimmed1LastSix = Col1Position[-6:]\n",
    "\n",
    "\n",
    "#Create validation logic that will be used in the Insert function\n",
    "\n",
    "  \n",
    "# creating a blank series \n",
    "Checker = pd.Series([]) \n",
    "  \n",
    "  \n",
    "  # running a for loop and asigning some values to series \n",
    "for i in range(len(data)): \n",
    "    if data[\"Type\"][i] == \"Grass\": \n",
    "        Type_new[i]=\"Green\"\n",
    "  \n",
    "    elif data[\"Type\"][i] == \"Fire\": \n",
    "        Type_new[i]=\"Orange\"\n",
    "  \n",
    "    elif data[\"Type\"][i] == \"Water\": \n",
    "        Type_new[i]=\"Blue\"\n",
    "  \n",
    "    else: \n",
    "        Type_new[i]= data[\"Type\"][i] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Start with first column until the loop below completes\n",
    "\n",
    "\n",
    "while Position1 <= df8columncount and Position2 <= df8columncount:\n",
    "    \n",
    "        \n",
    "        if Col1PositionTrimmed == Col2PositionTrimmed and Col1PositionTrimmed1LastSix == \"_File1\":\n",
    "        \n",
    "            #Create the name for the match column\n",
    "            #PositionMatchStr = (Col2PositionTrimmed + \" Match?\")\n",
    "\n",
    "            PositionMatchStr = (Col1PositionTrimmed, \" Match?\")\n",
    "\n",
    "            #insert the columns with the validation logic\n",
    "            #df7.insert(endofDF, PositionMatchStr, np.where(df7.iloc[:,Position1] == df7.iloc[:,Position2], 'yes', 'no'))\n",
    "            df7.insert(endofDF, PositionMatchStr, df7.iloc[:,Position1] == df7.iloc[:,Position2])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            endofDF = endofDF+1 \n",
    "            \n",
    "            #Move to the next position\n",
    "            Position1 = Position1+1            \n",
    "            Col1Position = df7.columns[Position1]\n",
    "            Col1PositionTrimmed = Col1Position[:-6]\n",
    "            Col1PositionTrimmed1LastSix = Col1Position[-6:]\n",
    "            \n",
    "            \n",
    "            #Reset the comparison column\n",
    "            Position2 = 0\n",
    "            Col2Position = df7.columns[Position2]\n",
    "            Col2PositionTrimmed = Col2Position[:-6]\n",
    "            \n",
    "        if Col1PositionTrimmed1LastSix != \"_File1\":\n",
    "            #Move to the next position\n",
    "            Position1 = Position1+1            \n",
    "            Col1Position = df7.columns[Position1]\n",
    "            Col1PositionTrimmed = Col1Position[:-6]\n",
    "            Col1PositionTrimmed1LastSix = Col1Position[-6:]\n",
    "            \n",
    "            #Reset the comparison column\n",
    "            Position2 = 0\n",
    "            Col2Position = df7.columns[Position2]\n",
    "            Col2PositionTrimmed = Col2Position[:-6]\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            #Move to next comparison column\n",
    "            Position2 = Position2+1\n",
    "            Col2Position = df7.columns[Position2]\n",
    "            Col2PositionTrimmed = Col2Position[:-6]\n",
    "\n",
    "#if column position ref 2 = column position ref1 run insert\n",
    "\n",
    "#if not check next column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print output into an excel workbook\n",
    "\n",
    "with pd.ExcelWriter('Validation_Results.xlsx') as writer:\n",
    "    \n",
    "    df.to_excel(writer, sheet_name='File_1', index=False)\n",
    "\n",
    "    df1.to_excel(writer, sheet_name='File_2', index=False)\n",
    "    \n",
    "    df3.to_excel(writer, sheet_name='Missing Rows File 1', index=False)\n",
    "    \n",
    "    df5.to_excel(writer, sheet_name='Missing Rows File 2', index=False)\n",
    "    \n",
    "    df6.to_excel(writer, sheet_name='Row Summary', index=False)\n",
    "\n",
    "    df7.to_excel(writer, sheet_name='Validation', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
